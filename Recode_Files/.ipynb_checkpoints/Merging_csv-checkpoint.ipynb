{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e738d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11413ce",
   "metadata": {},
   "source": [
    "change country between: PR, DR, CU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81478b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Chris\"\n",
    "country = \"DR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc2ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud\n",
      "['Sociodemográfica_202307260149_0_9a4647fcd3952859.epi7', '_informationdoorparticipants_202307260150_0_9a4647fcd3952859.epi7', '_household_202310280820_0_9a4647fcd3952859.epi7', '_informationdoor_202307260149_0_9a4647fcd3952859.epi7', '_mainhousehold_202307260150_0_9a4647fcd3952859.epi7', '.DS_Store', '_rosterhousehold_202307260150_0_9a4647fcd3952859.epi7', '_physical_exam_202307260149_0_9a4647fcd3952859.epi7', 'Neighborhood_202310280820_0_9a4647fcd3952859.epi7', 'Cognitiva_202310280820_0_9a4647fcd3952859.epi7', '_sociodemographic_202310280820_0_9a4647fcd3952859.epi7', '_cognitive_202307260150_0_9a4647fcd3952859.epi7', '_mainhousehold_202310280820_0_9a4647fcd3952859.epi7', 'Listas_202310280820_0_9a4647fcd3952859.epi7', '_nonresidentchildren_202310280820_0_9a4647fcd3952859.epi7', '_household_202307260150_0_9a4647fcd3952859.epi7', 'Cognitive_Scoring_202310280819_0_9a4647fcd3952859.epi7', 'Informante_202307260149_0_9a4647fcd3952859.epi7', 'Neighborhood_202307260150_0_9a4647fcd3952859.epi7', '_rosterhousehold_202310280820_0_9a4647fcd3952859.epi7', 'Received_Files_Checklist.xlsx', 'Door_202307260149_0_9a4647fcd3952859.epi7', 'Examen_Físico_202310280820_0_9a4647fcd3952859.epi7', 'Listas_202307260149_0_9a4647fcd3952859.epi7', 'csv', 'Cognitiva_202310280820_1_9a4647fcd3952859.epi7', 'Door_202310280820_0_9a4647fcd3952859.epi7', 'Sample_Contact_Investigation_202310280820_0_9a4647fcd3952859.epi7', '_informant_202307260150_0_9a4647fcd3952859.epi7', '_participants_202310280820_0_9a4647fcd3952859.epi7', 'Informante_202310280819_0_9a4647fcd3952859.epi7', 'Sociodemográfica_202310280820_0_9a4647fcd3952859.epi7', '_informationdoor_202310280820_0_9a4647fcd3952859.epi7', 'Examen_Físico_202307260150_0_9a4647fcd3952859.epi7', '_physical_exam_202310280820_0_9a4647fcd3952859.epi7', 'Familiar_202307260150_0_9a4647fcd3952859.epi7', '_sociodemographic_202307260149_0_9a4647fcd3952859.epi7', 'Cognitiva_202307260149_0_9a4647fcd3952859.epi7', '_informant_202310280820_0_9a4647fcd3952859.epi7', 'Sample_Contact_Investigation_202307260150_0_9a4647fcd3952859.epi7']\n"
     ]
    }
   ],
   "source": [
    "CU_directory = r\"/Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/cuba\"\n",
    "DR_directory = r\"/Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media\"\n",
    "\n",
    "if user == \"Chris\":\n",
    "    if country == \"DR\":\n",
    "        current_directory = DR_directory+\"/10_28_23_cloud\"\n",
    "        path1 = DR_directory+\"/10_28_23_cloud\"\n",
    "        path2 = DR_directory+\"/10_28_23_cloud/csv\"\n",
    "    elif country == \"CU\":\n",
    "        current_directory = CU_directory+\"\"\n",
    "        path1 = CU_directory+\"\"\n",
    "        path2 = CU_directory+\"\"\n",
    "elif user == \"Ty\":\n",
    "    current_directory = r\"C:\\Users\\Ty\\Desktop\\DataExport\"\n",
    "else:\n",
    "    print(\"Unknown user. Cannot set directory.\")\n",
    "    current_directory = None\n",
    "\n",
    "if current_directory:\n",
    "    os.chdir(current_directory)\n",
    "    file_list = os.listdir(current_directory)\n",
    "    print(f\"Changed directory to: {current_directory}\")\n",
    "    print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2a27c",
   "metadata": {},
   "source": [
    "Received files document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c536c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list1 :  ['_household_202310280820_0_9a4647fcd3952859.epi7', 'Neighborhood_202310280820_0_9a4647fcd3952859.epi7', '_sociodemographic_202310280820_0_9a4647fcd3952859.epi7', '_mainhousehold_202310280820_0_9a4647fcd3952859.epi7', 'Listas_202310280820_0_9a4647fcd3952859.epi7', '_nonresidentchildren_202310280820_0_9a4647fcd3952859.epi7', 'Cognitive_Scoring_202310280819_0_9a4647fcd3952859.epi7', '_rosterhousehold_202310280820_0_9a4647fcd3952859.epi7', 'Examen_Físico_202310280820_0_9a4647fcd3952859.epi7', 'Cognitiva_202310280820_1_9a4647fcd3952859.epi7', 'Door_202310280820_0_9a4647fcd3952859.epi7', '_participants_202310280820_0_9a4647fcd3952859.epi7', 'Informante_202310280819_0_9a4647fcd3952859.epi7', 'Sociodemográfica_202310280820_0_9a4647fcd3952859.epi7', '_informationdoor_202310280820_0_9a4647fcd3952859.epi7', '_physical_exam_202310280820_0_9a4647fcd3952859.epi7', '_informant_202310280820_0_9a4647fcd3952859.epi7']\n",
      "list2 :  ['_informationdoor_202310280820_0_9a4647fcd3952859.csv', '_informant_202307260150_0_9a4647fcd3952859.csv', '_cognitive_202307260150_0_9a4647fcd3952859.csv', '_mainhousehold_202310280820_0_9a4647fcd3952859.csv', '_participants_202310280820_0_9a4647fcd3952859.csv', '_sociodemographic_202307260149_0_9a4647fcd3952859.csv', 'Neighborhood_202310280820_0_9a4647fcd3952859.csv', 'Examen_Físico_202310280820_0_9a4647fcd3952859.csv', '_nonresidentchildren_202310280820_0_9a4647fcd3952859.csv', 'Listas_202310280820_0_9a4647fcd3952859.csv', 'Cognitive_Scoring_202310280819_0_9a4647fcd3952859.csv', '_informationdoorparticipants_202307260150_0_9a4647fcd3952859.csv', 'Door_202310280820_0_9a4647fcd3952859.csv', 'Informante_202310280819_0_9a4647fcd3952859.csv', '_physical_exam_202310280820_0_9a4647fcd3952859.csv', 'Cognitiva_202310280820_0_9a4647fcd3952859.csv', 'Familiar_202307260150_0_9a4647fcd3952859.csv', 'Sociodemográfica_202310280820_0_9a4647fcd3952859.csv', '_rosterhousehold_202307260150_0_9a4647fcd3952859.csv', '_household_202310280820_0_9a4647fcd3952859.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Door</th>\n",
       "      <th>_informationdoor_</th>\n",
       "      <th>_informationdoorparticipants</th>\n",
       "      <th>Listas</th>\n",
       "      <th>_mainhousehold</th>\n",
       "      <th>_participants</th>\n",
       "      <th>_rosterhousehold</th>\n",
       "      <th>_nonresidentchildren</th>\n",
       "      <th>Cognitva</th>\n",
       "      <th>_cognitive</th>\n",
       "      <th>Cognitive_Scoring</th>\n",
       "      <th>Examen_Físico</th>\n",
       "      <th>_physical_exam</th>\n",
       "      <th>Familiar</th>\n",
       "      <th>_household</th>\n",
       "      <th>Informante</th>\n",
       "      <th>_informant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neighborhood_202310280820_0_9a4647fcd3952859.csv</td>\n",
       "      <td>Door_202310280820_0_9a4647fcd3952859.csv</td>\n",
       "      <td>_informationdoor_202310280820_0_9a4647fcd39528...</td>\n",
       "      <td>_informationdoorparticipants_202307260150_0_9a...</td>\n",
       "      <td>Listas_202310280820_0_9a4647fcd3952859.csv</td>\n",
       "      <td>_mainhousehold_202310280820_0_9a4647fcd3952859...</td>\n",
       "      <td>_participants_202310280820_0_9a4647fcd3952859.csv</td>\n",
       "      <td>_rosterhousehold_202307260150_0_9a4647fcd39528...</td>\n",
       "      <td>_nonresidentchildren_202310280820_0_9a4647fcd3...</td>\n",
       "      <td>Falta</td>\n",
       "      <td>_cognitive_202307260150_0_9a4647fcd3952859.csv</td>\n",
       "      <td>Cognitive_Scoring_202310280819_0_9a4647fcd3952...</td>\n",
       "      <td>Examen_Físico_202310280820_0_9a4647fcd3952859...</td>\n",
       "      <td>_physical_exam_202310280820_0_9a4647fcd3952859...</td>\n",
       "      <td>Familiar_202307260150_0_9a4647fcd3952859.csv</td>\n",
       "      <td>_household_202310280820_0_9a4647fcd3952859.csv</td>\n",
       "      <td>Informante_202310280819_0_9a4647fcd3952859.csv</td>\n",
       "      <td>_informant_202307260150_0_9a4647fcd3952859.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Neighborhood  \\\n",
       "0  Neighborhood_202310280820_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                       Door  \\\n",
       "0  Door_202310280820_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                   _informationdoor_  \\\n",
       "0  _informationdoor_202310280820_0_9a4647fcd39528...   \n",
       "\n",
       "                        _informationdoorparticipants  \\\n",
       "0  _informationdoorparticipants_202307260150_0_9a...   \n",
       "\n",
       "                                       Listas  \\\n",
       "0  Listas_202310280820_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                      _mainhousehold  \\\n",
       "0  _mainhousehold_202310280820_0_9a4647fcd3952859...   \n",
       "\n",
       "                                       _participants  \\\n",
       "0  _participants_202310280820_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                    _rosterhousehold  \\\n",
       "0  _rosterhousehold_202307260150_0_9a4647fcd39528...   \n",
       "\n",
       "                                _nonresidentchildren Cognitva  \\\n",
       "0  _nonresidentchildren_202310280820_0_9a4647fcd3...    Falta   \n",
       "\n",
       "                                       _cognitive  \\\n",
       "0  _cognitive_202307260150_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                   Cognitive_Scoring  \\\n",
       "0  Cognitive_Scoring_202310280819_0_9a4647fcd3952...   \n",
       "\n",
       "                                      Examen_Físico  \\\n",
       "0  Examen_Físico_202310280820_0_9a4647fcd3952859...   \n",
       "\n",
       "                                      _physical_exam  \\\n",
       "0  _physical_exam_202310280820_0_9a4647fcd3952859...   \n",
       "\n",
       "                                       Familiar  \\\n",
       "0  Familiar_202307260150_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                       _household  \\\n",
       "0  _household_202310280820_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                       Informante  \\\n",
       "0  Informante_202310280819_0_9a4647fcd3952859.csv   \n",
       "\n",
       "                                       _informant  \n",
       "0  _informant_202307260150_0_9a4647fcd3952859.csv  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all files and directories\n",
    "dir_list1 = os.listdir(current_directory)\n",
    "\n",
    "# To see which files I received from the data manager\n",
    "newdir_list1 = [x for x in dir_list1 if x.endswith('.epi7')]\n",
    "\n",
    "# To see which files I was able to process with Epi Info tool\n",
    "dir_list2 = os.listdir(path2)\n",
    "newdir_list2 = [x for x in dir_list2 if x.endswith('.csv')]\n",
    "\n",
    "def remove_common(a, b):\n",
    "    for i in a[:]:\n",
    "        if i in b:\n",
    "            a.remove(i)\n",
    "            b.remove(i)\n",
    "\n",
    "    print(\"list1 : \", a)\n",
    "    print(\"list2 : \", b)\n",
    "\n",
    "remove_common(newdir_list1, newdir_list2)\n",
    "\n",
    "words_to_filter = [\"Neighborhood\", \"Door\", \"_informationdoor_\", \"_informationdoorparticipants\", \"Listas\", \"_mainhousehold\", \"_participants\", \"_rosterhousehold\", \"_nonresidentchildren\", \"Cognitva\", \"_cognitive\", \"Cognitive_Scoring\", \"Examen_Físico\", \"_physical_exam\",\"Familiar\", \"_household\", \"Informante\", \"_informant\"]\n",
    "\n",
    "# breaking the longer list into smaller lists\n",
    "filtered_lists = {word: [] for word in words_to_filter}\n",
    "\n",
    "for text in newdir_list2:\n",
    "    for word in words_to_filter:\n",
    "        if word in text:\n",
    "            filtered_lists[word].append(text)\n",
    "\n",
    "# change this number depending on how many tablets worth of information you're receiving\n",
    "for word, filtered_list in filtered_lists.items():\n",
    "    while len(filtered_list) < 1:\n",
    "        filtered_list.append(\"Falta\")\n",
    "\n",
    "Received_Files = pd.DataFrame()\n",
    "\n",
    "for word, filtered_list in filtered_lists.items():\n",
    "    Received_Files[word] = pd.Series(filtered_list)\n",
    "\n",
    "Received_Files.to_excel('Received_Files_Checklist.xlsx', index=False)\n",
    "\n",
    "Received_Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f6d39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_cognitive_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Cognitiva_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Cognitiva_202310280820_1_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Cognitiva_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Cognitive_Scoring_202310280819_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_household_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_household_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Familiar_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_physical_exam_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_physical_exam_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Examen_Físico_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Examen_Físico_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_informant_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_informant_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Informante_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Informante_202310280819_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_sociodemographic_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_sociodemographic_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Sociodemográfica_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Sociodemográfica_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Neighborhood_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Neighborhood_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Door_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Door_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_informationdoor_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_informationdoor_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_informationdoorparticipants_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Listas_202307260149_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/Listas_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_mainhousehold_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_mainhousehold_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_participants_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_rosterhousehold_202310280820_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_rosterhousehold_202307260150_0_9a4647fcd3952859.csv\n",
      "Processing /Users/chrissoria/Google Drive/Other Computers/My Laptop (1)/documents/cadas/data/CADAS data upload/Rep Dom/Sync Files + Media/10_28_23_cloud/csv/_nonresidentchildren_202310280820_0_9a4647fcd3952859.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_71507/1507612761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0msangre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0msangre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CSV_Merged/Sangre.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "folder_path = path2 #goes through this whole folder\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_cognitive*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "cog_child = pd.concat(dfs, ignore_index=True)\n",
    "cog_child = cog_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "cog_child.to_csv(\"CSV_Merged/Cog_Child.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Cognitiva*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "cog_parent = pd.concat(dfs, ignore_index=True)\n",
    "cog_parent = cog_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "cog_parent.to_csv(\"CSV_Merged/Cog_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Cognitive_Scoring*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "cog_scoring = pd.concat(dfs, ignore_index=True)\n",
    "cog_scoring = cog_scoring.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "cog_scoring.to_csv(\"CSV_Merged/Cog_Scoring.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_household*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "household_child = pd.concat(dfs, ignore_index=True)\n",
    "household_child = household_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "household_child.to_csv(\"CSV_Merged/Household_Child.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Familiar*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "household_parent = pd.concat(dfs, ignore_index=True)\n",
    "household_parent = household_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "household_parent.to_csv(\"CSV_Merged/Household_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_physical_exam*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "phys_child = pd.concat(dfs, ignore_index=True)\n",
    "phys_child = phys_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "phys_child.to_csv(\"CSV_Merged/Phys_Child.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Examen_Físico*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "phys_parent = pd.concat(dfs, ignore_index=True)\n",
    "phys_parent = phys_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "phys_parent.to_csv(\"CSV_Merged/Phys_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informant*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "infor_child = pd.concat(dfs, ignore_index=True)\n",
    "infor_child = infor_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "infor_child.to_csv(\"CSV_Merged/Infor_Child.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Informante*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "infor_parent = pd.concat(dfs, ignore_index=True)\n",
    "infor_parent = infor_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "infor_parent.to_csv(\"CSV_Merged/Infor_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_sociodemographic*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "socio_child = pd.concat(dfs, ignore_index=True)\n",
    "socio_child = socio_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "socio_child.to_csv(\"CSV_Merged/Socio_Child.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Sociodemográfica*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "socio_parent = pd.concat(dfs, ignore_index=True)\n",
    "socio_parent = socio_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "socio_parent.to_csv(\"CSV_Merged/Socio_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Neighborhood*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "neighborhood = pd.concat(dfs, ignore_index=True)\n",
    "neighborhood = neighborhood.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "neighborhood.to_csv(\"CSV_Merged/Neighborhood.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Door*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "door_parent = pd.concat(dfs, ignore_index=True)\n",
    "door_parent = door_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "door_parent.to_csv(\"CSV_Merged/Door.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informationdoor_*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "informationdoor = pd.concat(dfs, ignore_index=True)\n",
    "informationdoor = informationdoor.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "informationdoor.to_csv(\"CSV_Merged/InformationDoor.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informationdoorparticipants*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "informationdoorparticipants = pd.concat(dfs, ignore_index=True)\n",
    "informationdoorparticipants = informationdoorparticipants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "informationdoorparticipants.to_csv(\"CSV_Merged/InformationDoorParticipants.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Listas*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "rosters_parent = pd.concat(dfs, ignore_index=True)\n",
    "rosters_parent = rosters_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "rosters_parent.to_csv(\"CSV_Merged/Roster_Parent.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_mainhousehold*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "mainhousehold = pd.concat(dfs, ignore_index=True)\n",
    "mainhousehold = mainhousehold.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "mainhousehold.to_csv(\"CSV_Merged/MainHousehold.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_participants*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "participants = pd.concat(dfs, ignore_index=True)\n",
    "participants = participants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "participants.to_csv(\"CSV_Merged/Participants.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_rosterhousehold*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "nonparticipants = pd.concat(dfs, ignore_index=True)\n",
    "nonparticipants = nonparticipants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "nonparticipants.to_csv(\"CSV_Merged/NonParticipants.csv\")\n",
    "\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_nonresidentchildren*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "nonresidentchildren = pd.concat(dfs, ignore_index=True)\n",
    "nonresidentchildren = nonresidentchildren.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "nonresidentchildren.to_csv(\"CSV_Merged/NonResidentChildren.csv\")\n",
    "\n",
    "if country != \"Cuba\":\n",
    "    dfs = []  # list to hold all dataframes\n",
    "    for filename in glob.glob(os.path.join(folder_path, '*Sangre*.csv')):\n",
    "        print(f\"Processing {filename}\")\n",
    "        df = pd.read_csv(filename)\n",
    "        dfs.append(df)\n",
    "    sangre = pd.concat(dfs, ignore_index=True)\n",
    "    sangre.to_csv(\"CSV_Merged/Sangre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efa929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
