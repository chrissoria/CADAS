{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fde265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5b214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrissoria/Documents/Research/CADAS_Data_Export\n"
     ]
    }
   ],
   "source": [
    "current_directory = \"/Users/chrissoria/Documents/Research/CADAS_Data_Export\"\n",
    "\n",
    "os.chdir(current_directory)\n",
    "\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505d21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/chrissoria/Documents/Research/CADAS_Data_Export/CSV/_cognitive_202308021158_0_01_DO.csv\n",
      "Processing /Users/chrissoria/Documents/Research/CADAS_Data_Export/CSV/_cognitive_202308020801_0_02_DO.csv\n",
      "Processing /Users/chrissoria/Documents/Research/CADAS_Data_Export/CSV/_household_202308021158_0_01_DO.csv\n",
      "Processing /Users/chrissoria/Documents/Research/CADAS_Data_Export/CSV/_household_202308020801_0_02_DO.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"/Users/chrissoria/Documents/Research/CADAS_Data_Export/CSV\" #goes through this whole folder\n",
    "dfs = [] # list to hold all dataframes\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_cognitive*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "cog_child = pd.concat(dfs, ignore_index=True)\n",
    "cog_child = cog_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "cog_child.to_csv(\"CSV/Cog_Child.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Cognitiva*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "cog_parent = pd.concat(dfs, ignore_index=True)\n",
    "cog_parent = cog_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "cog_parent.to_csv(\"CSV/Cog_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_household*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "household_child = pd.concat(dfs, ignore_index=True)\n",
    "household_child = household_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "household_child.to_csv(\"CSV/Household_Child.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Familiar*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "household_parent = pd.concat(dfs, ignore_index=True)\n",
    "household_parent = household_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "household_child.to_csv(\"CSV/Household_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_physical_exam*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "phys_child = pd.concat(dfs, ignore_index=True)\n",
    "phys_child = phys_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "phys_child.to_csv(\"CSV/Phys_Child.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Examen_Físico*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "phys_parent = pd.concat(dfs, ignore_index=True)\n",
    "phys_parent = phys_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "phys_parent.to_csv(\"CSV/Phys_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informant*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "infor_child = pd.concat(dfs, ignore_index=True)\n",
    "infor_child = infor_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "infor_child.to_csv(\"CSV/Infor_Child.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Informante*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "infor_parent = pd.concat(dfs, ignore_index=True)\n",
    "infor_parent = infor_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "infor_parent.to_csv(\"CSV/Infor_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_sociodemographic*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "socio_child = pd.concat(dfs, ignore_index=True)\n",
    "socio_child = socio_child.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "socio_child.to_csv(\"CSV/Socio_Child.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Sociodemográfica*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "socio_parent = pd.concat(dfs, ignore_index=True)\n",
    "socio_parent = socio_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "socio_parent.to_csv(\"CSV/Socio_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Neighborhood*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "neighborhood = pd.concat(dfs, ignore_index=True)\n",
    "neighborhood = neighborhood.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "neighborhood.to_csv(\"CSV/Neighborhood.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Door*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "door_parent = pd.concat(dfs, ignore_index=True)\n",
    "door_parent = door_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "door_parent.to_csv(\"CSV/Door.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informationdoor*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "informationdoor = pd.concat(dfs, ignore_index=True)\n",
    "informationdoor = informationdoor.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "informationdoor.to_csv(\"CSV/InformationDoor.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_informationdoorparticipants*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "informationdoorparticipants = pd.concat(dfs, ignore_index=True)\n",
    "informationdoorparticipants = informationdoorparticipants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "informationdoorparticipants.to_csv(\"CSV/InformationDoorParticipants.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*Listas*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "rosters_parent = pd.concat(dfs, ignore_index=True)\n",
    "rosters_parent = rosters_parent.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "rosters_parent.to_csv(\"CSV/Roster_Parent.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_mainhousehold*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "mainhousehold = pd.concat(dfs, ignore_index=True)\n",
    "mainhousehold = mainhousehold.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "mainhousehold.to_csv(\"CSV/MainHousehold.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_participants*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "participants = pd.concat(dfs, ignore_index=True)\n",
    "participants = participants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "participants.to_csv(\"CSV/Participants.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_rosterhousehold*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "nonparticipants = pd.concat(dfs, ignore_index=True)\n",
    "nonparticipants = nonparticipants.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "nonparticipants.to_csv(\"CSV/NonParticipants.csv\")\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*_nonresidentchildren*.csv')):\n",
    "\n",
    "    print(f\"Processing {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "    \n",
    "nonresidentchildren = pd.concat(dfs, ignore_index=True)\n",
    "nonresidentchildren = nonresidentchildren.drop_duplicates(subset='GlobalRecordId', keep='first')\n",
    "\n",
    "nonresidentchildren.to_csv(\"CSV/NonResidentChildren.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
