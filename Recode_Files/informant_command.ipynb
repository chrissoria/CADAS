{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ae729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79682642",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/CADAS_1066/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffd6aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centreid</th>\n",
       "      <th>houseid</th>\n",
       "      <th>particid</th>\n",
       "      <th>houseid2</th>\n",
       "      <th>countryid</th>\n",
       "      <th>region</th>\n",
       "      <th>rural</th>\n",
       "      <th>date</th>\n",
       "      <th>interid</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>nparks</th>\n",
       "      <th>parkinsonism</th>\n",
       "      <th>walkdiff</th>\n",
       "      <th>vuln_inc</th>\n",
       "      <th>vuln_live1</th>\n",
       "      <th>chilocal</th>\n",
       "      <th>relweekly</th>\n",
       "      <th>frweekly</th>\n",
       "      <th>popvar</th>\n",
       "      <th>surveyok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-10-07 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-02 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-02 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   centreid  houseid  particid  houseid2  countryid  region  rural  \\\n",
       "0       1.0   1001.0       1.0  101001.0        1.0     1.0    0.0   \n",
       "1       1.0   1001.0       2.0  101001.0        1.0     1.0    0.0   \n",
       "2       1.0   1002.0       1.0  101002.0        1.0     1.0    0.0   \n",
       "3       1.0   1003.0       1.0  101003.0        1.0     1.0    0.0   \n",
       "4       1.0   1003.0       2.0  101003.0        1.0     1.0    0.0   \n",
       "\n",
       "                  date  interid   age  ...  nparks  parkinsonism  walkdiff  \\\n",
       "0  2003-09-05 00:00:00      1.0  72.0  ...     4.0           1.0       1.0   \n",
       "1  2003-10-07 00:00:00      1.0  77.0  ...     4.0           1.0       0.0   \n",
       "2  2003-09-01 00:00:00      1.0  65.0  ...     3.0           0.0       0.0   \n",
       "3  2003-09-02 00:00:00      1.0  87.0  ...     3.0           0.0       0.0   \n",
       "4  2003-09-02 00:00:00      1.0  85.0  ...     2.0           0.0       0.0   \n",
       "\n",
       "   vuln_inc  vuln_live1  chilocal  relweekly  frweekly  popvar  surveyok  \n",
       "0       3.0         1.0       1.0        1.0       0.0     1.0       1.0  \n",
       "1       2.0         1.0       1.0        1.0       1.0     1.0       1.0  \n",
       "2       3.0         3.0       0.0        0.0       1.0     1.0       1.0  \n",
       "3       3.0         3.0       0.0        NaN       1.0     1.0       1.0  \n",
       "4       2.0         3.0       0.0        NaN       0.0     1.0       1.0  \n",
       "\n",
       "[5 rows x 1231 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('data/1066_Baseline_data.dta', convert_categoricals=False)\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "variables = [\"mental\", \"activ\", \"memory\", \"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \n",
    "            \"wordfind\", \"wordwrg\", \"past\", \"lastsee\", \"lastday\", \"orient\", \"lostout\", \n",
    "            \"lostin\", \"chores\", \"hobby\", \"money\", \"change\", \"reason\", \"feed\", \"dress\", \"toilet\"]\n",
    "\n",
    "CADAS = []\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ddd1b",
   "metadata": {},
   "source": [
    "First, we recode this set of variable's missing values to 9 /\n",
    "From line 6-9 and 62-67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcbe2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_9 = [\"mental\", \"activ\", \"memory\", \"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \n",
    "            \"wordfind\", \"wordwrg\", \"past\", \"lastsee\", \"lastday\", \"orient\", \"lostout\", \n",
    "            \"lostin\", \"chores\", \"hobby\", \"money\", \"change\", \"reason\", \"feed\", \"dress\", \"toilet\"]\n",
    "\n",
    "for var in recode_9:\n",
    "    df[var] = df[var].fillna(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5a929",
   "metadata": {},
   "source": [
    "Then we count how many missing values there are in the bunch for each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d76213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "0     6755\n",
      "24      34\n",
      "1       22\n",
      "3       10\n",
      "2        4\n",
      "4        2\n",
      "6        1\n",
      "5        1\n",
      "13       1\n",
      "9        1\n",
      "7        1\n",
      "21       1\n",
      "Name: miss1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "miss1_variables = [\"mental\", \"activ\", \"memory\", \"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \n",
    "            \"wordfind\", \"wordwrg\", \"past\", \"lastsee\", \"lastday\", \"orient\", \"lostout\", \n",
    "            \"lostin\", \"chores\", \"hobby\", \"money\", \"change\", \"reason\"]\n",
    "\n",
    "df['miss1'] = df[variables].apply(lambda x: (x == 9).sum(), axis=1)\n",
    "\n",
    "print(len(miss1_variables))\n",
    "print(df['miss1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6497c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6755\n",
      "24      34\n",
      "1       22\n",
      "3       10\n",
      "2        4\n",
      "4        2\n",
      "6        1\n",
      "5        1\n",
      "13       1\n",
      "9        1\n",
      "7        1\n",
      "21       1\n",
      "Name: miss3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "miss3_variables = [\"feed\", \"dress\", \"toilet\"]\n",
    "\n",
    "df['miss3'] = df[variables].apply(lambda x: (x == 9).sum(), axis=1)\n",
    "\n",
    "print(df['miss3'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82511cb6",
   "metadata": {},
   "source": [
    "Then we multiple Miss3 times 3 and add it to Miss 1 \\\n",
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40360c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6755\n",
      "96      34\n",
      "4       22\n",
      "12      10\n",
      "8        4\n",
      "16       2\n",
      "24       1\n",
      "20       1\n",
      "52       1\n",
      "36       1\n",
      "28       1\n",
      "84       1\n",
      "Name: misstot, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['misstot'] = (df['miss3']*3) + df['miss1']\n",
    "\n",
    "print(df['misstot'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ba88c",
   "metadata": {},
   "source": [
    "Next, in this set of variables we half the score of 1 to .5 and 2 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3c1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_half = [\"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \"wordfind\", \"wordwrg\", \"past\", \n",
    "            \"lastsee\", \"lastday\", \"orient\", \"lostout\", \"lostin\", \"chores\", \"change\", \"money\"]\n",
    "\n",
    "for var in recode_half:\n",
    "    df[var] = df[var].apply(lambda x: 0.5 if x == 1 else (1 if x == 2 else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e519f",
   "metadata": {},
   "source": [
    "Now, we will save an original version of these variables so that we can manipulate a new version and not lose the old version \\\n",
    "Then we will recode all values of dress to 0 if dressdis equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df332cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_update = [\"dress\", \"chores\", \"feed\", \"toilet\"]\n",
    "disability_flags = [\"dressdis\", \"choredis\", \"feeddis\", \"toildis\"]\n",
    "\n",
    "for col, dis_flag in zip(columns_to_update, disability_flags):\n",
    "    df[f\"{col}_original\"] = df[col]\n",
    "    df[col] = df.apply(lambda row: 0 if row[dis_flag] == 1 else row[col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fec71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (\n",
    "    df['activ'] + df['mental'] + df['memory'] + df['put'] + df['kept'] + df['frdname'] + \n",
    "    df['famname'] + df['convers'] + df['wordfind'] + df['wordwrg'] + df['past'] + \n",
    "    df['lastsee'] + df['lastday'] + df['orient'] + df['lostout'] + df['lostin'] + \n",
    "    df['chores'] + df['hobby'] + df['money'] + df['change'] + df['reason'] + \n",
    "    df['feed'] + df['dress'] + df['toilet']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df['relscore'] = (30 / (30 - df['misstot'])) * s - ((df['miss1'] + df['miss3']) * 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cec2fb",
   "metadata": {},
   "source": [
    "Now we will add all of these components together to create a 'relative score' \\\n",
    "Why 30? Because 30 is the maximum amount of possible missing for the Misstot variable \\\n",
    "Essentially this is creating an inverse weighting based on the amount of missing data. If very little data is missing (misstot is small), the adjustment is close to 1 and does not adjust. \\\n",
    "Then we multiple this inverse weighting to the sum of variable in the s \\\n",
    "Finally, we apply a penalty based on how many missing responses there are multiplied by nine \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54622c4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{relscore} = \\left( \\frac{30}{30 - \\text{misstot}} \\right) \\times \\text{S} - (\\text{miss1} + \\text{miss3}) \\times 9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb59070",
   "metadata": {},
   "source": [
    "where S is the main score of interest \\\n",
    "$$\n",
    "\\text{S} = \\sum_{i=1}^{|S|} \\mathbf{v}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4dd1d2",
   "metadata": {},
   "source": [
    "miss1 is the sum of missing values from variables 1:18 in S\n",
    "\n",
    "$$\n",
    "\\text{miss1} = \\sum_{i=1}^{|Q|} I(\\mathbf{v}_i = 9)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e70ae",
   "metadata": {},
   "source": [
    "mis3 is the sum of missing values from variables 19:21 in S\n",
    "\n",
    "$$\n",
    "\\text{miss3} = \\sum_{i=1}^{|T|} I(\\mathbf{v}_i = 9)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627eb50",
   "metadata": {},
   "source": [
    "and, misstot is 3 times miss3 plus miss1 \\\n",
    "$$\n",
    "\\text{misstot} = 3 \\times \\text{miss3} + \\text{miss1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f937394",
   "metadata": {},
   "source": [
    "and everything all together:\n",
    "\n",
    "$$\n",
    "\\text{relscore} = \\left( \\frac{30}{30 - \\left[3 \\times \\sum_{i=1}^{|T|} I(\\mathbf{v}_i = 9) + \\sum_{i=1}^{|Q|} I(\\mathbf{v}_i = 9)\\right]} \\right) \\times \\sum_{i=1}^{|S|} \\mathbf{v}_i - \\left[\\sum_{i=1}^{|Q|} I(\\mathbf{v}_i = 9) + \\sum_{i=1}^{|T|} I(\\mathbf{v}_i = 9)\\right] \\times 9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe4715",
   "metadata": {},
   "source": [
    "Essentially what this is doing is inverse weighting the S vector (which is the sum of various cognitive measures) to reduce the weight of cases that have a lot of missingness in the s vector, and then applying an additional penalty on the S vector based on how many missing. \\\n",
    "\n",
    "relscore = A score of cognitive abilities adjusting for missing responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d32e24",
   "metadata": {},
   "source": [
    "Next, we'll recode this set of variables and double the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb0f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_double = [\"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \"wordfind\", \"wordwrg\", \"past\", \n",
    "             \"lastsee\", \"lastday\", \"orient\", \"lostout\", \"lostin\", \"chores\", \"change\", \"money\"]\n",
    "\n",
    "for var in recode_double:\n",
    "    df[var] = df[var].apply(lambda x: 1 if x == 0.5 else (2 if x == 1 else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c61456",
   "metadata": {},
   "source": [
    "below we convert all the 9's back to missing values (a step that is uneccesarry if we were to just create new versions for the algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d356bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_9 = [\"mental\", \"activ\", \"memory\", \"put\", \"kept\", \"frdname\", \"famname\", \"convers\", \n",
    "            \"wordfind\", \"wordwrg\", \"past\", \"lastsee\", \"lastday\", \"orient\", \"lostout\", \n",
    "            \"lostin\", \"chores\", \"hobby\", \"money\", \"change\", \"reason\", \"feed\", \"dress\", \"toilet\"]\n",
    "\n",
    "for var in recode_9:\n",
    "    df[var] = df[var].apply(lambda x: np.nan if x == 9 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9087930",
   "metadata": {},
   "source": [
    "THIS CORRECTS A GLITCH WHEREBY IF THE WHOLE CSI'D' INFORMANT INTERVIEW WAS MISSING A RELSCORE OF 0 WAS RETURNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "270f2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relscore'] = df.apply(lambda row: np.nan if row['misstot'] >= 29 else row['relscore'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560a1cd",
   "metadata": {},
   "source": [
    "below is the total srq score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c764ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['srqtot'] = 0\n",
    "\n",
    "for i in range(1, 21):\n",
    "    df['srqtot'] += df[f'srq{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e75f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['srqcase'] = df['srqtot'].apply(lambda x: 0 if 0 <= x <= 7 else (1 if x > 7 else np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a53f6ac",
   "metadata": {},
   "source": [
    "below we are counting both the 9 values and missing values to create a sum of all missing for the srq variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4501e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "srqlist = [\"srq1\", \"srq2\", \"srq3\", \"srq4\", \"srq5\", \"srq6\", \"srq7\", \"srq8\", \n",
    "            \"srq9\", \"srq10\", \"srq11\", \"srq12\", \"srq13\", \"srq14\", \"srq15\", \n",
    "            \"srq16\", \"srq17\", \"srq18\", \"srq19\", \"srq20\"]\n",
    "\n",
    "df['srqmiss'] = (df[srqlist].apply(lambda x: (x == 9).sum(), axis=1)) + (df[srqlist].apply(lambda x: (x == np.nan).sum(), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ade79f",
   "metadata": {},
   "source": [
    "below we recode values where srqmiss are greater than 10 in srqtot and srqcase to missing (adjusting the total score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e12a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['srqtot'] = df.apply(lambda row: np.nan if row['srqmiss'] >= 11 else row['srqtot'], axis = 1)\n",
    "\n",
    "df['srqcase'] = df.apply(lambda row: np.nan if row['srqmiss'] >= 11 else row['srqcase'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d230d",
   "metadata": {},
   "source": [
    "below we calculate the ZARIT CAREGIVER BURDEN \\\n",
    "First we count the missings in the zb columns \\\n",
    "Then we add up the 1's and inverse weight the total score for the zb columns \\\n",
    "Then we replace the 9's with na again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ac2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "zb_columns = [f'zb{i}' for i in range(1, 23)]\n",
    "df['zbmiss'] = df[zb_columns].apply(lambda x: (x == 9).sum(), axis=1) #count the missing\n",
    "\n",
    "df['zbtot'] = (22 / (22 - df['zbmiss'])) * (df[zb_columns].sum(axis=1) - (df['zbmiss'] * 9))\n",
    "\n",
    "df[zb_columns] = df[zb_columns].replace(9, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adcad4",
   "metadata": {},
   "source": [
    "CAREGIVER INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f40811",
   "metadata": {},
   "outputs": [],
   "source": [
    "cben_list = ['cben1','cben2','cben3','cben4']\n",
    "\n",
    "for var in cben_list:\n",
    "    df[var] = df[var].apply(lambda x: 0 if np.isnan(x) else (0 if x == 999999 else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc09129",
   "metadata": {},
   "source": [
    "below we are creating variables that we will later fill with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b9368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_create = [\n",
    "    'c_family1', 'c_family2', 'c_family3', 'c_family4',\n",
    "    'c_gov1', 'c_gov2', 'c_gov3', 'c_gov4',\n",
    "    'c_occup1', 'c_occup2', 'c_occup3', 'c_occup4',\n",
    "    'c_disab1', 'c_disab2', 'c_disab3', 'c_disab4',\n",
    "    'c_rent1', 'c_rent2', 'c_rent3', 'c_rent4',\n",
    "    'c_work1', 'c_work2', 'c_work3', 'c_work4',\n",
    "    'c_care1', 'c_care2', 'c_care3', 'c_care4',\n",
    "    'c_oth1', 'c_oth2', 'c_oth3', 'c_oth4'\n",
    "]\n",
    "\n",
    "for var in variables_to_create:\n",
    "    df[var] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491a452",
   "metadata": {},
   "source": [
    "bellow, we assign values to the variables created above depending on the values of cbntype \\\n",
    "we assign c_var# the value of c_ben# depending on the cbntype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf8b13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For c_familyX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 4, f'c_family{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_govX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 1, f'c_gov{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_occupX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 2, f'c_occup{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_disabX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 3, f'c_disab{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_rentX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 5, f'c_rent{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_workX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 6, f'c_work{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_careX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 7, f'c_care{i}'] = df[f'cben{i}']\n",
    "\n",
    "# For c_othX\n",
    "for i in range(1, 5):\n",
    "    df.loc[df[f'cbntype{i}'] == 8, f'c_oth{i}'] = df[f'cben{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fba9b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    df[f'cbntype{i}'] = df[f'cbntype{i}'].apply(lambda x: np.nan if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a230237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    df[f'cben{i}'] = df[f'cben{i}'].apply(lambda x: np.nan if x == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed4f1a",
   "metadata": {},
   "source": [
    "below we sum up the values from the variables created above \\\n",
    "later I will find out what these sums represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68d633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_family'] = df['c_family1'] + df['c_family2'] + df['c_family3'] + df['c_family4']\n",
    "df['c_gov'] = df['c_gov1'] + df['c_gov2'] + df['c_gov3'] + df['c_gov4']\n",
    "df['c_occup'] = df['c_occup1'] + df['c_occup2'] + df['c_occup3'] + df['c_occup4']\n",
    "df['c_disab'] = df['c_disab1'] + df['c_disab2'] + df['c_disab3'] + df['c_disab4']\n",
    "df['c_rent'] = df['c_rent1'] + df['c_rent2'] + df['c_rent3'] + df['c_rent4']\n",
    "df['c_work'] = df['c_work1'] + df['c_work2'] + df['c_work3'] + df['c_work4']\n",
    "df['c_care'] = df['c_care1'] + df['c_care2'] + df['c_care3'] + df['c_care4']\n",
    "df['c_oth'] = df['c_oth1'] + df['c_oth2'] + df['c_oth3'] + df['c_oth4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3eea45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_replace = ['c_family', 'c_gov', 'c_occup', 'c_disab', 'c_rent', 'c_work', 'c_care', 'c_oth']\n",
    "df[cols_to_replace] = df[cols_to_replace].fillna(0)\n",
    "\n",
    "# Compute the sum for cnof_tot, a sum of all varaibles except family\n",
    "df['cnof_tot'] = df['c_gov'] + df['c_occup'] + df['c_disab'] + df['c_rent'] + df['c_work'] + df['c_care'] + df['c_oth']\n",
    "\n",
    "# Compute the sum for c_tot, a sum of all variables in the list above\n",
    "df['c_tot'] = df['cnof_tot'] + df['c_family']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f3b45",
   "metadata": {},
   "source": [
    "below we compute the tw_dep score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "352babec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_count = ['am1', 'pm1', 'eve1', 'nite1', 'am2', 'pm2', 'eve2', 'nite2']\n",
    "df['twdepmiss'] = df[cols_to_count].isnull().sum(axis=1) + (df[cols_to_count] == 9).sum(axis=1)\n",
    "\n",
    "df['tw_dep'] = 1.5 * (df['am1'] + df['pm1'] + df['eve1'] + df['nite1'] + df['am2'] + df['pm2'] + df['eve2'] + df['nite2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222adb1b",
   "metadata": {},
   "source": [
    "below we compute the tadl score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f743fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_recode_9_to_0 = ['cashrs2', 'cashrs3', 'cashrs4', 'cashrs5', 'cashrs7', 'cashrs8']\n",
    "df[cols_to_recode_9_to_0] = df[cols_to_recode_9_to_0].replace({np.nan: 0, 9: 0})\n",
    "\n",
    "cols_to_recode_99_to_0 = ['cashrs1', 'cashrs6']\n",
    "df[cols_to_recode_99_to_0] = df[cols_to_recode_99_to_0].replace({np.nan: 0, 99: 0})\n",
    "\n",
    "df['tadl'] = df['cashrs2'] + df['cashrs3'] + df['cashrs4'] + df['cashrs5'] + df['cashrs7'] + df['cashrs8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904dd024",
   "metadata": {},
   "source": [
    "below we recode variables to system missing (recoding everything back to na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f9ee4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_dict = {\n",
    "    'caremar': {0: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan},\n",
    "    'carerage': {1: np.nan, 2: np.nan, 3: np.nan, 4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan, 10: np.nan, 99: np.nan},\n",
    "    'carerrel': {9: np.nan},\n",
    "    'careeduc': {6: np.nan, 9: np.nan},\n",
    "    'cjob': {9: np.nan},\n",
    "    'cjobcat': {0: np.nan, 10: np.nan, 11: np.nan, 12: np.nan, 13: np.nan, 14: np.nan, 15: np.nan},\n",
    "    'carehelp': {9: np.nan},\n",
    "    'carelive': {2: np.nan, 3: np.nan, 4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan},\n",
    "    'cutback': {9: np.nan, 3: 0},\n",
    "    'cutwhen': {999: np.nan},\n",
    "    'am1': {9: np.nan},\n",
    "    'am2': {9: np.nan},\n",
    "    'pm1': {9: np.nan},\n",
    "    'pm2': {9: np.nan},\n",
    "    'eve1': {9: np.nan},\n",
    "    'eve2': {9: np.nan},\n",
    "    'nite1': {9: np.nan},\n",
    "    'nite2': {9: np.nan},\n",
    "    'helpweek': {13: np.nan, 14: np.nan, 15: np.nan, 16: np.nan, 17: np.nan, 18: np.nan, 19: np.nan, 20: np.nan},\n",
    "    'helpjob': {0: np.nan, 9: np.nan},\n",
    "    'daypaid': {0: np.nan, 9: np.nan},\n",
    "    'ntpaid': {0: np.nan, 9: np.nan},\n",
    "    'cashrs2': {4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan},\n",
    "    'cashrs3': {4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan},\n",
    "    'cashrs4': {4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, 8: np.nan, 9: np.nan},\n",
    "    'cashrs5': {4: np.nan, 5: np.nan, 6: np.nan, 7: np.nan, }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8ee35",
   "metadata": {},
   "source": [
    "below we compute the zbcare score and carerev scores \\\n",
    "THIS CORRECTS A GLITCH WHEREBY PARTICIPANTS WERE CODED AS NEEDING NO CARE, BUT CARE SECTION WAS NOT SKIPPED AND CARE NEEDS WERE EVIDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f31f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summing values within a range (1 thru Highest) for specific columns\n",
    "cols_zbcare = ['zb' + str(i) for i in range(1, 23)]\n",
    "df['zbcare'] = df[cols_zbcare].apply(lambda x: (x >= 1).sum(), axis=1)\n",
    "\n",
    "cols_othcare = ['cashrs' + str(i) for i in range(1, 8)] + ['cutback', 'carehelp']\n",
    "df['othcare'] = df[cols_othcare].apply(lambda x: (x >= 1).sum(), axis=1)\n",
    "\n",
    "# Compute the sum for carerev\n",
    "df['carerev'] = df['zbcare'] + df['othcare']\n",
    "\n",
    "# Recoding specific values in carerev column\n",
    "df['carerev'] = df['carerev'].apply(lambda x: 1 if x >= 1 else x)\n",
    "\n",
    "# Conditionally recoding values in CARENEED column\n",
    "df.loc[df['carerev'] == 1, 'careneed'] = df.loc[df['carerev'] == 1, 'careneed'].replace(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d8be1",
   "metadata": {},
   "source": [
    "THIS THEN RECODES CARE SECTION VARIABLES TO SYSMIS WHEN NO NEEDS FOR CARE WERE IDENTIFIED \\\n",
    "need to locate the careneed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf7a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_recode = ['carewho1', 'carewho2', 'cutback', 'cutwhen', 'cuthour', 'carehelp', 'helphour', 'helpweek', \n",
    "                  'helpjob', 'daypaid', 'ntpaid', 'cashrs1', 'cashrs2', 'cashrs3', 'cashrs4', 'cashrs5', \n",
    "                  'cashrs6', 'cashrs7', 'cashrs8'] + ['zb' + str(i) for i in range(1, 23)]\n",
    "\n",
    "# Conditionally recoding values\n",
    "df.loc[df['careneed'] == 3, cols_to_recode] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d17eb",
   "metadata": {},
   "source": [
    "NPI-Q DISTRESS AND SEVERITY SCORES (this will be in the algo) \\\n",
    "First, we recode all missing values in npisev and npidis to 0 (so that na doesn't prevent the calculations from running)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8c38d",
   "metadata": {},
   "source": [
    "What is the NPI? \\\n",
    "A measure of behavioural and psychological symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce610ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling out one so I can see what it's doing\n",
    "#this is recoding npi severity and npi distress to 0 if the main npi question is 0\n",
    "#in other words, when someone answers that the symptom is not present, we treat the following questions about it as 0  \n",
    "df['npi1sev'] = df.apply(lambda row: 0 if row['npi1'] == 0 and pd.isna(row['npi1sev']) else row['npi1sev'], axis=1)\n",
    "df['npi1d'] = df.apply(lambda row: 0 if row['npi1'] == 0 and pd.isna(row['npi1d']) else row['npi1d'], axis=1)\n",
    "\n",
    "#recoding all the values of npi_sev\n",
    "for i in range(1, 13):\n",
    "    npi_col = f'npi{i}'\n",
    "    sev_col = f'npi{i}sev'\n",
    "    \n",
    "    df.loc[(df[npi_col] == 0) & df[sev_col].isna(), sev_col] = 0 #here we are setting any missing scores for severity to 0\n",
    "\n",
    "#recoding all rest of the values the dis columnm\n",
    "for i in range(2, 13):\n",
    "    npi_col = f'npi{i}'\n",
    "    dis_col = f'npi{i}dis'\n",
    "    \n",
    "    df.loc[(df[npi_col] == 0) & df[dis_col].isna(), dis_col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d989746",
   "metadata": {},
   "source": [
    "then below we are recoding all 9's to missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to recode\n",
    "cols_to_recode = ['npi1', 'npi1sev', 'npi1d', 'npi2', 'npi2sev', 'npi2dis', \n",
    "                  'npi3', 'npi3sev', 'npi3dis', 'npi4', 'npi4sev', 'npi4dis', \n",
    "                  'npi5', 'npi5sev', 'npi5dis', 'npi6', 'npi6sev', 'npi6dis', \n",
    "                  'npi7', 'npi7sev', 'npi7dis', 'npi8', 'npi8sev', 'npi8dis', \n",
    "                  'npi9', 'npi9sev', 'npi9dis', 'npi10', 'npi10sev', 'npi10dis', \n",
    "                  'npi11', 'npi11sev', 'npi11dis', 'npi12', 'npi12sev', 'npi12dis']\n",
    "\n",
    "# Recode values\n",
    "df[cols_to_recode] = df[cols_to_recode].replace(9, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb733ee",
   "metadata": {},
   "source": [
    "next, we checking the severity (SEV) of each NPI variable. If the severity is greater than or equal to 1, it's recoding the corresponding NPI variable to 1 if its value is 2 or higher. \\\n",
    "This appears to be cleaning the variable in case any responses are not in the 0,1 binary that they should be in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1e60478",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13):  # Looping from 1 to 12\n",
    "    npi = f'npi{i}'\n",
    "    sev = f'npi{i}sev'\n",
    "    \n",
    "    mask = df[sev] >= 1\n",
    "    df.loc[mask, npi] = np.where(df.loc[mask, npi] >= 2, 1, df.loc[mask, npi])\n",
    "\n",
    "\n",
    "#then we recode anything that remian higher than a 2 as na\n",
    "for var in npi_vars:\n",
    "    df[var] = df[var].apply(lambda x: np.nan if x > 1 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d14ee5",
   "metadata": {},
   "source": [
    "then below we finally create the npi severity and npi distress scores based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2590b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of severity scores\n",
    "df['npisev'] = df['npi1sev'] + df['npi2sev'] + df['npi3sev'] + df['npi4sev'] + df['npi5sev'] + df['npi6sev'] + df['npi7sev'] + df['npi8sev'] + df['npi9sev'] + df['npi10sev'] + df['npi11sev'] + df['npi12sev']\n",
    "\n",
    "# Compute the sum of distress scores\n",
    "df['npidis'] = df['npi1d'] + df['npi2dis'] + df['npi3dis'] + df['npi4dis'] + df['npi5dis'] + df['npi6dis'] + df['npi7dis'] + df['npi8dis'] + df['npi9dis'] + df['npi10dis'] + df['npi11dis'] + df['npi12dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a054d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timeons'] = df['timeons'].apply(lambda x: np.nan if x == 999 else (np.nan if x == 0 else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186292fc",
   "metadata": {},
   "source": [
    "below we recode all 9's back to 9 (might be redundant, but leaving just to be safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53226801",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [\n",
    "    'typeons', 'ons1', 'ons2', 'ons3', 'ons4', 'ons5', 'ons6', 'ons7', 'ons8', 'ons9', 'ons10', 'ons11', 'ons12',\n",
    "    'ons13', 'ons14', 'ons15', 'ons16', 'ons17', 'ons18', 'ons19', 'ons20', 'ons21', 'ons221', 'fluct', 'fluctcog',\n",
    "    'fluctoft', 'graddec', 'stepwise', 'steppre1', 'steppre3', 'steppre2', 'steppre4', 'steprec1', 'steprec3', 'steprec2',\n",
    "    'steprec4', 'clouding', 'confnite', 'confday', 'nocturn', 'bchange', 'bsuspic', 'birrit', 'baccuse', 'bupset', 'bfirst',\n",
    "    'bvis', 'baud', 'bdelude', 'depress', 'depdur', 'cry', 'crydur', 'wishdie', 'interest', 'anhed', 'sleep', 'eat',\n",
    "    'bereave', 'berwhen', 'depimp', 'toldbp', 'treatbp', 'cvevent', 'cvtype1', 'cvtype2', 'cvtype3', 'cvtype4', 'affincon',\n",
    "    'angina', 'intclaud', 'midiag', 'park', 'tremor', 'initiate', 'slow', 'microg', 'heavyalc', 'alctreat', 'alcprob',\n",
    "    'hypothy', 'hyperthy', 'hi', 'hill', 'loc', 'behchang', 'fitsever', 'longfits', 'earlychg', 'npi1', 'npi1sev', 'npi1d',\n",
    "    'npi2', 'npi2sev', 'npi2dis', 'npi3', 'npi3sev', 'npi3dis', 'npi4', 'npi4sev', 'npi4dis', 'npi5', 'npi5sev', 'npi5dis',\n",
    "    'npi6', 'npi6sev', 'npi6dis', 'npi7', 'npi7sev', 'npi7dis', 'npi8', 'npi8sev', 'npi8dis', 'npi9', 'npi9sev', 'npi9dis',\n",
    "    'npi10', 'npi10sev', 'npi10dis', 'npi11', 'npi11sev', 'npi11dis', 'npi12', 'npi12sev', 'npi12dis', 'hasconf'\n",
    "]\n",
    "\n",
    "for var in all_vars:\n",
    "    df[var] = df[var].apply(lambda x: np.nan if x == 9 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ons221'] == 0, 'ons221'] = np.nan\n",
    "df.loc[df['depdur'] == 0, 'depdur'] = np.nan\n",
    "df.loc[df['cvtype1'] == 0, 'cvtype1'] = np.nan\n",
    "df.loc[df['cvtype2'] == 0, 'cvtype2'] = np.nan\n",
    "df.loc[df['cvtype3'] == 0, 'cvtype3'] = np.nan\n",
    "df.loc[df['cvtype4'] == 0, 'cvtype4'] = np.nan\n",
    "df.loc[df['loc'] == 0, 'loc'] = np.nan\n",
    "df.loc[df['berwhen'] == 0, 'berwhen'] = np.nan\n",
    "\n",
    "df.loc[df['fluctoft'] >= 5, 'fluctoft'] = np.nan\n",
    "\n",
    "for col in ['cvtype1', 'cvtype2', 'cvtype3', 'cvtype4', 'loc']:\n",
    "    df.loc[df[col] >= 3, col] = np.nan\n",
    "\n",
    "for col in ['affincon', 'earlychg']:\n",
    "    df.loc[df[col] >= 2, col] = np.nan\n",
    "\n",
    "for col in ['step1', 'step3', 'step2', 'step4', 'fallsno']:\n",
    "    df.loc[df[col] == 99, col] = np.nan\n",
    "\n",
    "for col in ['cvdate1', 'cvdate2', 'cvdate3', 'cvdate4', 'alcpast', 'alcnow']:\n",
    "    df.loc[df[col] == 999, col] = np.nan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
