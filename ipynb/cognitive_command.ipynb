{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826e42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2106f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/CADAS_1066/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8d161f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centreid</th>\n",
       "      <th>houseid</th>\n",
       "      <th>particid</th>\n",
       "      <th>houseid2</th>\n",
       "      <th>countryid</th>\n",
       "      <th>region</th>\n",
       "      <th>rural</th>\n",
       "      <th>date</th>\n",
       "      <th>interid</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>nparks</th>\n",
       "      <th>parkinsonism</th>\n",
       "      <th>walkdiff</th>\n",
       "      <th>vuln_inc</th>\n",
       "      <th>vuln_live1</th>\n",
       "      <th>chilocal</th>\n",
       "      <th>relweekly</th>\n",
       "      <th>frweekly</th>\n",
       "      <th>popvar</th>\n",
       "      <th>surveyok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-10-07 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-02 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-09-02 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   centreid  houseid  particid  houseid2  countryid  region  rural  \\\n",
       "0       1.0   1001.0       1.0  101001.0        1.0     1.0    0.0   \n",
       "1       1.0   1001.0       2.0  101001.0        1.0     1.0    0.0   \n",
       "2       1.0   1002.0       1.0  101002.0        1.0     1.0    0.0   \n",
       "3       1.0   1003.0       1.0  101003.0        1.0     1.0    0.0   \n",
       "4       1.0   1003.0       2.0  101003.0        1.0     1.0    0.0   \n",
       "\n",
       "                  date  interid   age  ...  nparks  parkinsonism  walkdiff  \\\n",
       "0  2003-09-05 00:00:00      1.0  72.0  ...     4.0           1.0       1.0   \n",
       "1  2003-10-07 00:00:00      1.0  77.0  ...     4.0           1.0       0.0   \n",
       "2  2003-09-01 00:00:00      1.0  65.0  ...     3.0           0.0       0.0   \n",
       "3  2003-09-02 00:00:00      1.0  87.0  ...     3.0           0.0       0.0   \n",
       "4  2003-09-02 00:00:00      1.0  85.0  ...     2.0           0.0       0.0   \n",
       "\n",
       "   vuln_inc  vuln_live1  chilocal  relweekly  frweekly  popvar  surveyok  \n",
       "0       3.0         1.0       1.0        1.0       0.0     1.0       1.0  \n",
       "1       2.0         1.0       1.0        1.0       1.0     1.0       1.0  \n",
       "2       3.0         3.0       0.0        0.0       1.0     1.0       1.0  \n",
       "3       3.0         3.0       0.0        NaN       1.0     1.0       1.0  \n",
       "4       2.0         3.0       0.0        NaN       0.0     1.0       1.0  \n",
       "\n",
       "[5 rows x 1231 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('data/1066_Baseline_data.dta', convert_categoricals=False)\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df.to_csv('data/1066_Baseline_data.csv')\n",
    "\n",
    "#here I'm building a variable match list\n",
    "variable_list = ['pencil', 'watch', 'chair', 'shoes', 'knuckle', 'elbow', 'should', 'bridge', 'hammer', \n",
    "                 'pray', 'chemist', 'repeat', 'town', 'chief', 'street', 'store', 'address', 'longmem', \n",
    "                 'month', 'day', 'year', 'season', 'nod', 'point', 'circle', 'pentag','animals','wordimm','worddel',\n",
    "                'paper','story','learn1','learn2','learn3','recall']\n",
    "\n",
    "CADAS_match = ['c_24','c_25','c_48','c_49','c_50','c_51','c_52','c_53','c_54','c_55','c_56','c_26','c_8',\n",
    "               'c_70 (CU/DR)/c_71(PR)','c_58','c_59','c_60','c_3','c_5','c_61',\n",
    "               'c_3','c_5','c_61','c_62,','c_72_1','c_32','c_40','sum of c_11-13','sum of c_21-23','sum of c_27-29',\n",
    "              'sum of c_66','c_33,','c_34','c_35','c_63']\n",
    "\n",
    "data = {'Variable': variable_list, 'CADAS_Match': CADAS_match}\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('../CADAS/10_66_algo_var_match.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe69624",
   "metadata": {},
   "source": [
    "Below, we are sorting by house id and particpant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2474dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['houseid', 'particid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a3f1f",
   "metadata": {},
   "source": [
    "Next, we want to pull out the name recall scores. What does this tell me?\n",
    "\n",
    "According to the table below, 6650 people were able to at least repeat the name of the interviewer once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd97fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6650\n",
      "0     183\n",
      "Name: nametot, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['nametot'] = 0\n",
    "\n",
    "#c_0 in CADAS\n",
    "df['nametot'] = np.where(df['name'] > 0, 1, df['nametot']) #I'm assuming this is where someone is asked to repeat a name\n",
    "#c_65 in CADAS\n",
    "df['nametot'] = np.where(df['nrecall'] > 0, 1, df['nametot']) #I'm assuming this is the name recall from cognitve\n",
    "\n",
    "print(df['nametot'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3d8ff",
   "metadata": {},
   "source": [
    "Next, it looks like we're calcuting a score based on different tests in the cognitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23c09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of 1s in specific columns\n",
    "df['count'] = df[['pencil', 'watch', 'chair', 'shoes', 'knuckle', 'elbow', 'should', 'bridge', 'hammer', \n",
    "                 'pray', 'chemist', 'repeat', 'town', 'chief', 'street', 'store', 'address', 'longmem', \n",
    "                 'month', 'day', 'year', 'season', 'nod', 'point', 'circle', 'pentag']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d5367",
   "metadata": {},
   "source": [
    "Next, we want to recode all missing values to 0 in order that the algo doesn't break (however, a bettter solution is possible?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c319e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recoding values from na to 0\n",
    "\n",
    "columns_to_replace_sysmis = ['animals', 'wordimm', 'worddel', 'paper', 'story', 'learn1', 'learn2', \n",
    "                             'learn3', 'recall', 'pencil', 'watch', 'chair', 'shoes', 'knuckle', 'elbow', \n",
    "                             'should', 'bridge', 'hammer', 'pray', 'chemist', 'repeat', 'town', 'chief', \n",
    "                             'street', 'store', 'address', 'longmem', 'month', 'day', 'year', 'season', \n",
    "                             'nod', 'point', 'circle', 'pentag', 'nametot', 'nrecall']\n",
    "\n",
    "for col in columns_to_replace_sysmis:\n",
    "    df[col] = df[col].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07ea62",
   "metadata": {},
   "source": [
    "recoding 9's and 99's to 0, I'll have to look at the codebook but i think this may be no sabe\n",
    "However, there are neither in paper, story, worddel, wordimn, and no 99 in any. This line of code is pretty superflous for this data but maybe not for ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d390c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace_99 = ['animals','wordimm','worddel','paper','story']\n",
    "\n",
    "columns_to_replace_9 = ['wordimm','worddel','paper','story']\n",
    "\n",
    "for col in columns_to_replace_99:\n",
    "    df[col] = df[col].replace(99, 0)\n",
    "    \n",
    "for col in columns_to_replace_9:\n",
    "    df[col] = df[col].replace(9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce80d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_recode = ['learn1', 'learn2', 'learn3', 'recall']\n",
    "\n",
    "for col in columns_to_recode:\n",
    "    # Map specific values\n",
    "    df[col] = df[col].replace(11, 1)\n",
    "    df[col] = df[col].replace({20: 2, 21: 2})\n",
    "    df[col] = df[col].replace({30: 3, 31: 3})\n",
    "    df[col] = df[col].replace({40: 4, 41: 4})\n",
    "    df[col] = df[col].replace({50: 5, 51: 5})\n",
    "    df[col] = df[col].replace({60: 6, 61: 6})\n",
    "    df[col] = df[col].replace({70: 7, 71: 7})\n",
    "    df[col] = df[col].replace({80: 8, 81: 8})\n",
    "    df[col] = df[col].replace({90: 9, 91: 9})\n",
    "    # Map 99 to sysmis (in pandas, we usually use NaN from the numpy library to represent missing data)\n",
    "    df[col] = df[col].replace(99, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96933706",
   "metadata": {},
   "source": [
    "Let's recode any value greater than 1 and less than 10 to a missing value. In other words, this removes anything that isn't correct or incorrect (such as no pudo, errors, etc). Really, the less than an equal to 9 function is superflous, and should be any number greater than 2 for this set of questions. However, we will leave it since that's what the original code has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe31a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_recode = ['name', 'pencil', 'watch', 'chair', 'shoes', 'knuckle', 'elbow', \n",
    "                     'should', 'bridge', 'hammer', 'pray', 'chemist', 'repeat', 'town', \n",
    "                     'chief', 'street', 'store', 'address', 'longmem', 'month', 'day', \n",
    "                     'year', 'season', 'nod', 'point', 'circle', 'pentag']\n",
    "\n",
    "for col in columns_to_recode:\n",
    "    df[col] = df[col].apply(lambda x: np.nan if 2 <= x <= 9 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb0ae1",
   "metadata": {},
   "source": [
    "Next, let's assume that any numbers greater than the numbers in the second list, corresponding to the variables in the first list, are errors and treat them ass missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fffdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_var = ['animals','wordimm','worddel','paper','story','recall','immed','nrecall']\n",
    "greater_than_number = [45,3,3,3,6,10,29,1]\n",
    "\n",
    "for col, num in zip(greater_than_var, greater_than_number):\n",
    "    df[col] = df[col].apply(lambda x: np.nan if x > num else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fc973",
   "metadata": {},
   "source": [
    "Now, we will divide the scores by the possible perfect score in order to get a number that's 1 or less. Question for Will, why is the animals question divided by 23 when it's possible to give an answer above that? We last recoded to allow the greatest number to be 45 (some 40's in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178bac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_var = ['animals','wordimm','worddel','paper','story']\n",
    "divisor = [23,3,3,3,6]\n",
    "new_column = ['animtot','wordtot1','wordtot2','papertot','storytot']\n",
    "\n",
    "for col,num,new in zip(divide_var,divisor,new_column):\n",
    "    df[new] = df[col]/num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f74741",
   "metadata": {},
   "source": [
    "Below, we will calculate the global cognitive score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc632469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of cogscore: 0.0 to 33.76222826086956\n"
     ]
    }
   ],
   "source": [
    "df['cogscore'] = 1.03125 * (df['nametot'] + df['count'] + df['animtot'] + df['wordtot1'] + \n",
    "                            df['wordtot2'] + df['papertot'] + df['storytot'])\n",
    "\n",
    "min_value = df['cogscore'].min()\n",
    "max_value = df['cogscore'].max()\n",
    "\n",
    "print(f\"Range of cogscore: {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5026ceba",
   "metadata": {},
   "source": [
    "Next, an immediate recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d164a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['immed'] = df['learn1'] + df['learn2'] + df['learn3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ff2f9",
   "metadata": {},
   "source": [
    "language expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d01bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['langexpr'] = df['bridge'] + df['hammer'] + df['pray'] + df['chemist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c44f0",
   "metadata": {},
   "source": [
    "language comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa6693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['langcomp'] = df['nod'] + df['point']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab57c84",
   "metadata": {},
   "source": [
    "orientation in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d652061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['orientti'] = df['month'] + df['day'] + df['year'] + df['season']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b2692",
   "metadata": {},
   "source": [
    "orientation in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2147845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['orientsp'] = df['town'] + df['street'] + df['store'] + df['address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c169428",
   "metadata": {},
   "source": [
    "object name identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c71c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['objname'] = df['pencil'] + df['watch'] + df['chair'] + df['shoes'] + df['knuckle'] + df['elbow'] + df['should']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d9bb1",
   "metadata": {},
   "source": [
    "memory (combined delayed and immediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "009b34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mem'] = df['worddel'] + df['wordimm'] + df['nrecall'] + df['story']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0bc27",
   "metadata": {},
   "source": [
    "a language score (combining language expression and comprehension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ebc1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['langexpr'] + df['langcomp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e2339",
   "metadata": {},
   "source": [
    "finally, an overall orientation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0403ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['orientat'] = df['orientti'] + df['orientsp'] + df['chief']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead4cdf",
   "metadata": {},
   "source": [
    "Next, we perform the imputation (based on a linear regression) \\\n",
    "pred_recall=0.344×immed−0.339 \\\n",
    " \\\n",
    "Coefficient of immed (0.344): This value represents the weight or importance of the immed variable in predicting recall. Specifically, for every one-unit increase in immed, the predicted recall score increases by approximately 0.344 units, all else being constant. \\\n",
    " \\\n",
    "Constant Term (-0.339): This is the y-intercept or the baseline value of predicted recall when immed is zero. This means if someone has a short-term memory score (immed) of 0, their predicted recall would be -0.339 (we will adjust 0 to be the floor) \\\n",
    " \\\n",
    "The equation assumes that there's a linear relationship between short-term memory (immed) and the variable we are trying to impute (likely some measure of recall). This relationship is derived from observed data where both variables are known. \\\n",
    "Basically, we are using the predictive power of immediate recall questions to fill in the blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8618089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of pred_recall: 0.0 to 9.636999999999999\n"
     ]
    }
   ],
   "source": [
    "df['pred_recall'] = (.344*df['immed'])-.339\n",
    "df['pred_recall'] = df['pred_recall'].apply(lambda x: 0 if x < 0 else (10 if x > 10 else x))\n",
    "\n",
    "min_value = df['pred_recall'].min()\n",
    "max_value = df['pred_recall'].max()\n",
    "\n",
    "print(f\"Range of pred_recall: {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127f0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.000     1270\n",
      "4.000     1203\n",
      "3.000      924\n",
      "6.000      918\n",
      "7.000      580\n",
      "2.000      574\n",
      "0.000      553\n",
      "1.000      333\n",
      "8.000      303\n",
      "9.000      106\n",
      "10.000      54\n",
      "3.445        2\n",
      "4.477        2\n",
      "5.509        2\n",
      "4.821        2\n",
      "3.789        1\n",
      "2.413        1\n",
      "4.133        1\n",
      "5.853        1\n",
      "7.573        1\n",
      "7.917        1\n",
      "5.165        1\n",
      "Name: recall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['recall'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b489e20c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.000     1270\n",
      "4.000     1203\n",
      "3.000      924\n",
      "6.000      918\n",
      "7.000      580\n",
      "2.000      574\n",
      "0.000      553\n",
      "1.000      333\n",
      "8.000      303\n",
      "9.000      106\n",
      "10.000      54\n",
      "3.445        2\n",
      "4.477        2\n",
      "5.509        2\n",
      "4.821        2\n",
      "3.789        1\n",
      "2.413        1\n",
      "4.133        1\n",
      "5.853        1\n",
      "7.573        1\n",
      "7.917        1\n",
      "5.165        1\n",
      "Name: recall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['recall_original'] = df['recall'] #keeping the original\n",
    "\n",
    "df['recall'] = df['recall'].apply(lambda x: 999 if np.isnan(x) else x)\n",
    "\n",
    "print(df['recall'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a83a4d",
   "metadata": {},
   "source": [
    "below we are taking the missing values, which we recoded to 999, and slotting in the predicted value for recall based on the regression above. Now, all people, including missing inputs, have a value for recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b305f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of recall: 0.0 to 10.0\n"
     ]
    }
   ],
   "source": [
    "df['recall'] = df['recall'].apply(lambda x: df['pred_recall'] if x == 999 else x)\n",
    "df['recall'] = df['recall'].apply(lambda x: np.nan if x > 11 else x)\n",
    "\n",
    "min_value = df['recall'].min()\n",
    "max_value = df['recall'].max()\n",
    "\n",
    "print(f\"Range of recall: {min_value} to {max_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
